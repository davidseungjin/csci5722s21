{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('envPy38': venv)",
   "metadata": {
    "interpreter": {
     "hash": "b7c5b5fbc15636ab8392b9a5c4abb8eb422181e9605eec6ad2b9311209df8478"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import tkinter.filedialog as fd\n",
    "import os\n",
    "import shutil\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "class finalProject:\n",
    "    def __init__(self):\n",
    "        # Variables\n",
    "        self.filesToBeProcessed = []                                # File(s) selected from file or folder open\n",
    "        self.sourceDirectory = \"\"                                   # Location of source folder. will be used when copying files\n",
    "        self.initialfolder = \"/Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/\"\n",
    "        self.objectvar = \"\"                                         # will be assigned in myGUI function\n",
    "        self.processedDict = {}                                     # All detection result according to object\n",
    "        self.filesAfterProcessed = []                               # Extracted list according to self.objectvar and source images (self.filesToBeProcessed)\n",
    "        self.targetDirectory = \"\"                                   # Folder that we want to store the extracted images\n",
    "        self.copyprogress = \"\"                                      # Any sentence that informs the progress\n",
    "        \n",
    "        self.yoloweights = self.initialfolder + \"yolo/yolov3_training_4000.weights\"\n",
    "        self.yolo_cfg = self.initialfolder + \"yolo/yolov3_training.cfg\"\n",
    "        self.coconames = self.initialfolder + \"yolo/classes.names\"\n",
    "        with open(self.coconames, \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "        self.myCNNnetwork = \"\"                                      # will be assigned by the function yolo_initiation\n",
    "        self.outputlayers = \"\"                                      # will be assigned by the function yolo_initiation\n",
    "        self.blob = \"\"                                              # will be assigned by the function yolo_blob(self, img)\n",
    "        self.outs = \"\"                                              # will be assigned by the function output\n",
    "        \n",
    "        self.myGUI()\n",
    "\n",
    "    def myGUI(self):\n",
    "        # Tkinter Part\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"CSCI5722 FinalProject\")\n",
    "\n",
    "        self.overview = tk.LabelFrame(self.root, text = \"Instruction\")\n",
    "        self.overview.pack(fill=\"both\", expand=\"yes\", padx=10, pady=10)\n",
    "        label1 = ttk.Label(self.overview, text=\"Step1: select files or folder\").pack()\n",
    "        label2 = ttk.Label(self.overview, text=\"Step2: select target object\").pack()\n",
    "        label3 = ttk.Label(self.overview, text=\"Step3: assign target folder\").pack()\n",
    "\n",
    "        self.first_frame = tk.LabelFrame(self.root, text = \"Step1: Opening files\")\n",
    "        self.first_frame.pack(fill=\"both\", expand=\"yes\", padx=10, pady=10)\n",
    "        openingfiles = ttk.Button(self.first_frame, text=\"Files\", command= lambda: self.opening_files()).pack()\n",
    "        openingfolder = ttk.Button(self.first_frame, text=\"Folder\", command= lambda: self.opening_dir()).pack()\n",
    "\n",
    "\n",
    "        self.second_frame = tk.LabelFrame(self.root, text = \"Step2-1: Near-Duplicate\")\n",
    "        self.second_frame.pack(fill=\"both\", expand=\"yes\", padx=10, pady=10)\n",
    "        ttk.Button(self.second_frame, text=\"Detect: Near-Duplicate\", command = lambda: self.nearDuplicate()).pack()\n",
    "\n",
    "\n",
    "        self.third_frame = tk.LabelFrame(self.root, text = \"Step2-2: Detect Objects\")\n",
    "        self.third_frame.pack(fill=\"both\", expand=\"yes\", padx=10, pady=10)\n",
    "        \n",
    "        ttk.Button(self.third_frame, text=\"CNN Processing\", command= lambda: self.detection()).pack()\n",
    "        self.objectvar = tk.StringVar()\n",
    "        tk.Radiobutton(self.third_frame, text=\"Person\", variable = self.objectvar, value = \"Person\").pack()\n",
    "        tk.Radiobutton(self.third_frame, text=\"Car\", variable = self.objectvar, value = \"Car\").pack()\n",
    "        tk.Radiobutton(self.third_frame, text=\"Flower\", variable = self.objectvar, value = \"Flower\").pack()\n",
    "        tk.Radiobutton(self.third_frame, text=\"Tree\", variable = self.objectvar, value = \"Tree\").pack()\n",
    "        tk.Radiobutton(self.third_frame, text=\"Rock\", variable = self.objectvar, value = \"Rock\").pack()\n",
    "        tk.Radiobutton(self.third_frame, text=\"Water\", variable = self.objectvar, value = \"Water\").pack()\n",
    "        tk.Radiobutton(self.third_frame, text=\"Effel Tower\", variable = self.objectvar, value = \"Effel Tower\").pack()\n",
    "        tk.Radiobutton(self.third_frame, text=\"Scene\", variable = self.objectvar, value = \"Scene\").pack()\n",
    "        ttk.Button(self.third_frame, text=\"Extract photo with topic above\", command= lambda: self.detectionObject()).pack()\n",
    "\n",
    "        # bottom_frame = tk.Frame(self.root).pack()\n",
    "        self.fourth_frame = tk.LabelFrame(self.root, text = \"Step3: assign a folder to copy the sorted photos\")\n",
    "        self.fourth_frame.pack(fill=\"both\", expand=\"yes\", padx=10, pady=10)\n",
    "        openingfolder2 = tk.Button(self.fourth_frame, text=\"Folder\", command = lambda: self.assign_dir()).pack()\n",
    "\n",
    "        # myentry = tk.Label(self.fourth_frame, bd = 5).pack()\n",
    "        label8 = tk.Label(self.fourth_frame, text=\"files will be copied to the folder assigned\").pack()\n",
    "        copytofolder = tk.Button(self.fourth_frame, text=\"Copy\", command = lambda: self.copytofolder()).pack()\n",
    "        self.label9 = tk.Label(self.fourth_frame, text=self.copyprogress).pack()\n",
    "        \n",
    "        \n",
    "        self.quit_frame = tk.LabelFrame(self.root, text = \"Quit Program\")\n",
    "        self.quit_frame.pack(fill=\"both\", expand=\"yes\", padx=10, pady=10)\n",
    "        label10 = tk.Button(self.quit_frame, text=\"Quit\", command=quit).pack()\n",
    "        \n",
    "        self.root.mainloop()\n",
    "\n",
    "    def opening_files(self) -> list:\n",
    "        # Tkinter object creation to handle files selection, directory selection.\n",
    "        self.filesToBeProcessed = list(fd.askopenfilenames(initialdir = self.initialfolder, title='Choose a file'))\n",
    "\n",
    "        # print(\"myfiles = \", self.filesToBeProcessed, type(self.filesToBeProcessed))\n",
    "        \n",
    "\n",
    "    def opening_dir(self) -> list:\n",
    "        # When directory selection.\n",
    "        \n",
    "        self.sourceDirectory = fd.askdirectory(initialdir = self.initialfolder, title = 'Choose a directory')\n",
    "        self.filesToBeProcessed = [os.path.join(self.sourceDirectory, files) for files in os.listdir(self.sourceDirectory) if os.path.isfile(os.path.join(self.sourceDirectory, files)) ]\n",
    "\n",
    "        # print(\"dourceDirectory, filesToBeProcessed are\", self.sourceDirectory, self.filesToBeProcessed)\n",
    "        # print(\"len of files are \", len(self.filesToBeProcessed))\n",
    "\n",
    "    def nearDuplicate():\n",
    "        print(\"NEAR DUPLICATE FUNCTION\")\n",
    "\n",
    "    def detectionObject(self) -> list:\n",
    "        self.filesAfterProcessed = []\n",
    "        # print(\"detectionObject. detection function start\")\n",
    "        # self.detection()\n",
    "        keyword = self.objectvar.get().lower()\n",
    "        if keyword in self.processedDict.keys():\n",
    "            self.filesAfterProcessed = list(self.processedDict[keyword].keys())\n",
    "        else:\n",
    "            print(\"Your query {} is not in the processedDict.\".format(keyword))\n",
    "                    \n",
    "\n",
    "    def assign_dir(self) -> None:\n",
    "        # When directory selection.\n",
    "        # It processes each files in the directory to create file path string and store in a list.\n",
    "\n",
    "        self.targetDirectory = fd.askdirectory(initialdir = self.initialfolder, title = 'Choose a directory')\n",
    "        print(\"directory selected is \", self.targetDirectory, type(self.targetDirectory))\n",
    "\n",
    "    def copytofolder(self):\n",
    "        # files = [os.path.split(myfile)[1] for myfile in self.filesAfterProcessed]          # if index 0, then it is the path of file\n",
    "        # files = [os.path.split(myfile)[1] for myfile in self.filesToBeProcessed]\n",
    "        for elem in self.filesAfterProcessed:\n",
    "            print(\"sct, dst \", elem, os.path.join(self.targetDirectory, os.path.split(elem)[1]))\n",
    "            shutil.copyfile(elem, os.path.join(self.targetDirectory, os.path.split(elem)[1]))\n",
    "        # self.copyprogress = \"Copy completed\" <-- How to update text of Label from \"\" to \"Copy completed\" OR \"Copy started\" -> \"Copy completed\"\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def yolo_initiation(self):\n",
    "        # print(\"yolo_initiation function called\")\n",
    "        # yoloweights = self.yoloweights\n",
    "        # yolo_cfg = self.yolo_cfg\n",
    "        self.myCNNnetwork = cv.dnn.readNet(self.yoloweights, self.yolo_cfg)\n",
    "\n",
    "        layer_names = self.myCNNnetwork.getLayerNames()\n",
    "        self.outputlayers = [layer_names[i[0] - 1] for i in self.myCNNnetwork.getUnconnectedOutLayers()]\n",
    "        # print(\"yolo_initiation function finished\")\n",
    "        # print(\"myCNNnetwork and outputlayers are\", self.myCNNnetwork, self.outputlayers)\n",
    "\n",
    "\n",
    "    def loading_img(self, file):\n",
    "        # Loading image\n",
    "        img = cv.imread(file)\n",
    "        img = cv.resize(img, None, fx=0.2, fy=0.2) \n",
    "        return img\n",
    "\n",
    "    def yolo_blob(self, img):\n",
    "        # Detecting objects\n",
    "        # blob = cv.dnn.blobFromImage(img, 0.004, (img.shape[1], img.shape[0]), (0,0,0), True, crop=False)\n",
    "        # The model has been trained for different sizes of images: 320 x 320 (high speed, less accuracy), 416 x 416 (moderate speed, moderate accuracy) and 608 x 608 (less speed, high accuracy)\n",
    "        # https://towardsdatascience.com/object-detection-using-yolov3-and-opencv-19ee0792a420\n",
    "        self.blob = cv.dnn.blobFromImage(img, 0.00392, (608,608), (0,0,0), True, crop=False)        \n",
    "\n",
    "    def misc_blob_check(self):\n",
    "        for b in self.blob:\n",
    "            for n, img_b in enumerate(b):\n",
    "                cv.imshow(str(n), img_b)\n",
    "\n",
    "    def output(self):\n",
    "        self.myCNNnetwork.setInput(self.blob)\n",
    "        self.outs = self.myCNNnetwork.forward(self.outputlayers)\n",
    "        # print(\"self.outs in output func is \", self.outs)\n",
    "\n",
    "    def detection(self):\n",
    "        self.yolo_initiation()\n",
    "        # print(\"fileToBeProcessed is \", self.filesToBeProcessed)\n",
    "        for myfile in self.filesToBeProcessed:\n",
    "            try:\n",
    "                img = self.loading_img(myfile)\n",
    "                self.yolo_blob(img)\n",
    "                self.output()\n",
    "                self.nms_result(img, myfile)\n",
    "            except:\n",
    "                print(\"########## Except raised. Maybe Not image files ##########\")\n",
    "                continue\n",
    "\n",
    "    def nms_result(self, img, myfile) -> None:\n",
    "        '''\n",
    "        After detecting objects from img using outs layers already pre-trained\n",
    "        it updates global variable mydict declared in main function\n",
    "        format I design is \n",
    "        {'people': [file A, file B], 'chair': [file A, file C]} ...\n",
    "        '''\n",
    "        height, width, _ = img.shape\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "\n",
    "        for out in self.outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = float(scores[class_id])\n",
    "                if confidence > 0.3:\n",
    "                    # Object detected\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    # cv.circle(img, (center_x, center_y), 20, (0,0,255), 2)\n",
    "                    # Rectangle coordinates\n",
    "                    x = int(center_x - w // 2)\n",
    "                    y = int(center_y - h // 2)\n",
    "\n",
    "                    boxes.append([x,y,w,h])\n",
    "                    confidences.append(confidence)\n",
    "                    class_ids.append(class_id)\n",
    "                    # cv.rectangle(img, (x, y), (x + w, y + h), (0,0,255), 2)\n",
    "\n",
    "        # Non maxima suppression\n",
    "        if confidences:\n",
    "            print(len(confidences), type(confidences))\n",
    "        else:\n",
    "            print(\"No object captured with this confidence condition\")\n",
    "\n",
    "        # Boxes value should be int, and confidences values should be float, not np.float.\n",
    "        indexes = cv.dnn.NMSBoxes(boxes, confidences, 0.3, 0.3)\n",
    "        \n",
    "        for i in indexes:\n",
    "            i = i[0]            # it's because indexes are list of list. components are [int]\n",
    "            # If mydict has the object key already, then secondly check mydict[object] has file key\n",
    "            # If it meet these two condition, then increase value 1 otherwise create file: 0 as key/value pair of\n",
    "            # mydict[object]\n",
    "            # If there is no object key in mydict, create mydict[object] = {file : 0}\n",
    "            if self.classes[class_ids[i]] in self.processedDict.keys():\n",
    "                if myfile in self.processedDict[self.classes[class_ids[i]]].keys():\n",
    "                    self.processedDict[self.classes[class_ids[i]]][myfile] += 1\n",
    "                else:\n",
    "                    self.processedDict[self.classes[class_ids[i]]][myfile] =1\n",
    "            else:\n",
    "                self.processedDict[self.classes[class_ids[i]]] = {myfile:1}\n",
    "        \n",
    "        # for k1, v1 in self.processedDict.items():\n",
    "        #     for k2, v2 in v1.items():\n",
    "        #         print(\"Item {}: File {} contains {}\".format(k1, k2, v2))\n",
    "        \n",
    "        '''\n",
    "        This below is for visualizing into img and show. For Final project, it's not the scope.\n",
    "        '''\n",
    "        # for i in range(len(boxes)):\n",
    "        #     if i in indexes:\n",
    "        #         x, y, w, h = boxes[i]\n",
    "        #         label = classes[class_ids[i]]\n",
    "        #         # print(type(label))\n",
    "        #         cv.rectangle(img, (x,y), (x+w, y+h), (0,0,255),2)\n",
    "        #         cv.putText(img, label, (x, y-h//2+20), cv.FONT_HERSHEY_PLAIN, 1, (0,0,255),2)\n",
    "\n",
    "        # cv.imshow(\"Image\", img)\n",
    "        # cv.waitKey(0)\n",
    "        # cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2 <class 'list'>\n",
      "1 <class 'list'>\n",
      "3 <class 'list'>\n",
      "No object captured with this confidence condition\n",
      "No object captured with this confidence condition\n",
      "No object captured with this confidence condition\n",
      "No object captured with this confidence condition\n",
      "No object captured with this confidence condition\n",
      "No object captured with this confidence condition\n",
      "No object captured with this confidence condition\n",
      "No object captured with this confidence condition\n",
      "23 <class 'list'>\n",
      "20 <class 'list'>\n",
      "17 <class 'list'>\n",
      "23 <class 'list'>\n",
      "24 <class 'list'>\n",
      "34 <class 'list'>\n",
      "21 <class 'list'>\n",
      "19 <class 'list'>\n",
      "22 <class 'list'>\n",
      "21 <class 'list'>\n",
      "4 <class 'list'>\n",
      "22 <class 'list'>\n",
      "21 <class 'list'>\n",
      "23 <class 'list'>\n",
      "2 <class 'list'>\n",
      "13 <class 'list'>\n",
      "No object captured with this confidence condition\n",
      "directory selected is  /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/test <class 'str'>\n",
      "sct, dst  /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/PhotoSorter_images/20160601_111919.jpg /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/test/20160601_111919.jpg\n",
      "sct, dst  /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/PhotoSorter_images/20160601_111922.jpg /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/test/20160601_111922.jpg\n",
      "sct, dst  /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/PhotoSorter_images/20160601_111929.jpg /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/test/20160601_111929.jpg\n",
      "sct, dst  /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/PhotoSorter_images/20160601_111931.jpg /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/test/20160601_111931.jpg\n",
      "sct, dst  /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/PhotoSorter_images/20160601_112831.jpg /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/test/20160601_112831.jpg\n",
      "sct, dst  /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/PhotoSorter_images/20160601_112833.jpg /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/test/20160601_112833.jpg\n",
      "sct, dst  /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/PhotoSorter_images/20160601_112838.jpg /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/test/20160601_112838.jpg\n",
      "sct, dst  /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/PhotoSorter_images/20160601_112840.jpg /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/test/20160601_112840.jpg\n",
      "sct, dst  /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/PhotoSorter_images/20160601_112848.jpg /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/test/20160601_112848.jpg\n",
      "sct, dst  /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/PhotoSorter_images/20160601_112849.jpg /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/test/20160601_112849.jpg\n",
      "sct, dst  /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/PhotoSorter_images/20160706_111435.jpg /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/test/20160706_111435.jpg\n",
      "sct, dst  /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/PhotoSorter_images/20160706_111437.jpg /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/test/20160706_111437.jpg\n",
      "sct, dst  /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/PhotoSorter_images/20160706_111438.jpg /Volumes/extSSD/02_Classes/20_CSCI 5722 Computer Vision/HWs/csci5722s21/FinalProject/test/20160706_111438.jpg\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f2dc432dd83e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinalProject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-c52e70e68e3c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m                                              \u001b[0;31m# will be assigned by the function output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmyGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c52e70e68e3c>\u001b[0m in \u001b[0;36mmyGUI\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mlabel10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mButton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Quit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopening_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/tkinter/__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a = finalProject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.targetDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}